{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aa324b9-0036-48d7-a4a4-b8e3301021ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Day67_DBX_Spark_Egress[write] - json\n",
    "## Serialized Files - Datalake\n",
    "### ORC, Parquet, delta (hive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82aa7516-d6db-4e1d-9b81-85d436d7cfd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# extract\n",
    "ingest_df1=spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/source/custs_header\",header=True,inferSchema=True)\n",
    "display(ingest_df1.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22735a75-3176-44f8-a38f-e7ab963803a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#major write formats \n",
    "##structured (csv)\n",
    "##semi-structured (json/xml)\n",
    "##datalake (serialized files(parquet,orc,delta))\n",
    "##lakehouse (table(delta/hive tables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6333c4d-5130-4bb2-952a-6bf13b8e7c96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Serialization is a Data Mechanics\n",
    "- mostly used in Bigdata\n",
    "- Encoding format performant for savin space + processing inteligent bigdata format\n",
    "- Binary format (Brainy file format) / byte code\n",
    "  - orc, parquet, **delta (databricks properatory)**  => columnar formats\n",
    "  - orc optimized row column fo\n",
    "  - parquest tiled data format\n",
    "  - delta enriched parquet; delta (change/modification) operations can be performed(DML **ACID property**)\n",
    "- Benefits: fast, compact, interoperable, extensible, scalable , secured\n",
    "  - FAst - brings only required\n",
    "  - Compact - stores data more compactly\n",
    "  - Interoperable - works in various systems\n",
    "- by default orc/parquet uses snappy compression\n",
    "  - compression='zlib', 'lzo', 'gzip'.. in write operation  \n",
    "- Deserilize - uncompression\n",
    "\n",
    "## other Data Mechanics\n",
    "- Encoding / Decoding\n",
    "- Compress / Decompress: eg snappy - good compressor in bigdata\n",
    "- Encrypt / Decrypt\n",
    "- Masking / redaction (encoding without decoding - non reversable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ae9904a-f3fe-4eb0-ac8c-283df47fb74a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### delta -> developed on top of parquest with advancedc features by databricks\n",
    "- with some additional files we can in the storage\n",
    "  - log info, what change happend, incremental changes,.. \n",
    "\n",
    "- Now its not directly supported by spark like orc and parquest; we have to use format('delta') option\n",
    "  - df.wrtie.orc()\n",
    "  - df.wrtie.parquet()\n",
    "  - df.wrtie.format('delta') ; other serialized not directly supported by spark are avero, iceberg .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d692e7d5-a3b8-4906-9c31-6660cb98df60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# orc\n",
    "ingest_df1.write.orc(\"/Volumes/workspace/wd36schema/ingestion_volume/target/orcout\",mode='overwrite')\n",
    "# parquet\n",
    "ingest_df1.write.parquet(\"/Volumes/workspace/wd36schema/ingestion_volume/target/parquetout\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cfe742c-9f79-4e19-bec0-3ea1ee58fa49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.orc(\"/Volumes/workspace/wd36schema/ingestion_volume/target/orcout\").where(\"profession='Pilot'\").display()\n",
    "## orc will bring only required data unlike csv it will fetch nall data then apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "230a7cfe-aee0-401d-a842-e05f84f21f2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# explain the plan\n",
    "spark.read.orc(\"/Volumes/workspace/wd36schema/ingestion_volume/target/orcout\").where(\"profession='Pilot'\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39fe09e2-1cb3-4eb7-83b8-49a593c1ad97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",sep='~').show()\n",
    "spark.read.csv(\"/Volumes/workspace/wd36schema/ingestion_volume/target/csvout\",sep='~').where(\"_c3='Pilot'\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26514d44-b127-4509-b497-0a4027deaed7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day67_DBX_Spark_Egress[write] serialized files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
